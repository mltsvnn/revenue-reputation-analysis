# Эконометрический анализ влияния онлайн-репутации на выручку сетей косметики
**Проект демонстрирует полный цикл анализа панельных данных** для оценки влияния репутационных и макроэкономических факторов на годовую выручку крупнейших российских сетей косметики (2015–2024 гг.). Включает сбор и агрегирование данных (репутационные метрики, поисковая активность, макроиндикаторы, финансовые показатели), построение и диагностику эконометрических моделей (Pooled OLS, Fixed/Random Effects), интерпретацию результатов и практические рекомендации.

---
# Содержание репозитория

- ## **data/**  
В папке `data/` хранится файл `df_aggregated.csv` — итоговая агрегированная таблица, содержащая ежегодные метрики по 9 крупным сетям за период 2015–2024 гг. Данные можно разделить на несколько групп: отзывы пользователей, поисковая активность, макроэкономические индикаторы и финансовые показатели.

Ниже подробно описаны группы факторов, их источники и итоговые переменные.

| Группа данных           | Источник / сбор                        | Агрегирование                         | Итоговые переменные (имя в CSV)                         | Описание и единицы                      |
|-------------------------|----------------------------------------|---------------------------------------|--------------------------------------------------------|-----------------------------------------|
| **Отзывы**              | Otzovik, Яндекс.Карты  | Сбор «сырых» отзывов по каждому магазину сети, затем годовая агрегация по сети | `avg_rating`<br>`review_vol`<br>`neg_share`<br>`avg_sentiment`<br>`AvgLikes`<br>`VarRating` | - `avg_rating` (float): средний звёздочный рейтинг за год по сети <br>- `review_vol` (int): общее число отзывов за год<br>- `neg_share` (float): доля негативных отзывов (доля отзывов с оценкой ≤2 звезды)<br>- `avg_sentiment` (float): средняя тональность отзывов по результатам NLP-анализа текста <br>- `AvgLikes` (float): среднее число реакций на один отзыв за год<br>- `VarRating` (float): дисперсия рейтингов внутри года, отражает разброс оценок |
| **Поисковая активность**| Google Trends (через Pytrends)         | Выборка ежемесячных значений Interest for Topic/Brand, затем усреднение по 12 месячным показателям за год | `search_index`                                         | `search_index` (float, 0–100): годовой индекс интереса к бренду в Google Trends. Значение 100 соответствует пику за весь период, 0 — минимальный уровень. |
| **Макроэкономика**      | Росстат             | Годовые значения по РФ (фиксируются на уровне всей экономики, одинаковы для всех сетей) | `cp_index`<br>`income_pop`<br>`FemaleShare`            | - `cp_index` (float): индекс потребительских цен (CPI) на конец года <br>- `income_pop` (float): реальные располагаемые доходы населения, годовое изменение в процентах<br>- `FemaleShare` (float): доля женщин в общей численности населения РФ (%). |
| **Финансовые показатели** | Отчёты компаний, пресс-релизы, аналитические обзоры, базы данных (audit-it, РБК, публичные финансовые отчёты) | Ежегодная выручка по сети: сбор из различных источников, корректировка на инфляцию, конвертация в однородную единицу (млн или млрд руб.) | `revenue`<br>   | - `revenue` (float): годовая выручка сети в миллионах (или миллиардах) рублей <br>-  |
| **Дополнительные переменные** | Вычисляются на этапе эконометрического моделирования | создаются лог-преобразования | `ln_revenue`<br>`ln_search_index`<br>`ln_review_vol` | ln_revenue: натуральный логарифм годовой выручки (revenue > 0). Применён для стабилизации дисперсии и интерпретации коэффициентов как эластичностей.<br> ln_search_index: натуральный логарифм индекса поисковой активности. Обычно рассчитывают как ln(search_index + 1) (или +ε), чтобы корректно обработать нулевые значения и снизить скошенность распределения. <br> ln_review_vol: натуральный логарифм объёма отзывов за год. Вычисляется как ln(review_vol + 1) (или +ε) для учёта случаев, когда review_vol может быть 0, и для более нормального распределения в модели. |

> **Примечание** В репозитории хранится только итоговый агрегированный CSV. «Сырые» выгрузки отзывов имеют значительный объём (около 95 000 записей). При необходимости сбор этих данных можно воспроизвести с помощью примеров в scripts/ , но для воспроизведения эконометрического анализа достаточно агрегированного датасета.

- ## **scripts/**

Папка `scripts/` содержит примеры «скелетного» кода для сбора «сырых» отзывов с онлайн-сервисов:

- `parse_yandex_maps.py` — шаблон парсера отзывов из Яндекс.Карт.
- `parse_otzovik.py` — шаблон парсера отзывов с Otzovik.

### Выбор источников обусловлен

- **Объёмом и доступностью отзывов**: обе платформы имеют значительный пул отзывов по сетям косметики, что позволило накопить около 95 000 записей «сырых» отзывов до агрегации.  
- **Разнообразием форматов**: Яндекс.Карты даёт локационные отзывы (мнения реальных точек продаж), Otzovik —  развернутые отзывы потребителей о брендах, вместе они обеспечивают более полное представление об онлайн-репутации.  
- **Репрезентативностью**: сочетание платформ помогает учесть разные сегменты аудитории: локальных покупателей офлайн-точек и онлайн-пользователей, что повышает корректность выводов эконометрического анализа.

### Особенности и дисклеймер

- Опубликованные скрипты демонстрируют лишь архитектуру парсера с Selenium: настройка браузера, навигация по страницам, поиск элементов, сбор данных (текст, рейтинг, год, реакции).  
- **Работоспособность селекторов** требует актуализации: HTML-структура сайтов меняется, поэтому перед запуском необходимо проверить и адаптировать CSS-селекторы.  
- **Captcha и ограничения**: возможны проверки со стороны площадок; парсер может требовать ручного решения CAPTCHA или пауз между запросами.  
- **Правила использования**: перед реальным сбором следует убедиться в соответствии с условиями использования платформ, чтобы не нарушать их политику.  
- **Сбор не обязателен для анализа**: агрегированный датасет хранится в `data/df_aggregated.csv`. Для воспроизведения эконометрического анализа достаточно готовых агрегатов. Парсеры предоставлены как отправная точка, а не «рабочий» код «из коробки».

### Запуск и адаптация

1. Установить зависимости ( `selenium`, `pandas` и т. д.) и ChromeDriver или иной WebDriver, совместимый с браузером.  
2. Проверить и при необходимости скорректировать:
   - Список начальных URL или логику поиска магазинов/товаров.  
   - CSS-селекторы для элементов страницы (отзыв, автор, дата, рейтинг, текст, реакции).  
3. При сборе соблюдать разумные интервалы между действиями (sleep, human-like scroll), чтобы снизить риск блокировки.  
4. Собранные «сырые» отзывы сохранять локально (например, в JSON/Excel), затем агрегировать в годовые метрики в Jupyter Notebook.  
  
- **notebooks/**  
  Главный ноутбук `panel_analysis.ipynb`, в котором:
  1. Загружаются и инспектируются данные.
  2. Выполняется предобработка (лог-преобразования, создание нужных переменных, проверка выбросов).
  3. Проводятся диаграммы и корреляционные матрицы для первичной диагностики.
  4. Строятся модели панельных данных: Pooled OLS (с и без робастных ошибок), Fixed Effects, Random Effects.
  5. Проводятся тесты предпосылок: нормальность остатков, гетероскедастичность, автокорреляция, мультиколлинеарность, тест Хаусмана для выбора FE vs RE.
  6. Интерпретируются результаты, выводятся ключевые коэффициенты и эластичности в лог-спецификациях.
  7. Формулируются бизнес-рекомендации на основе значимых факторов.

 





## Установка и запуск

1. **Клонирование репозитория**  
   - Откройте терминал (Command Prompt/PowerShell на Windows, Terminal на macOS/Linux).  
   - Выполните:
     ```bash
     git clone https://github.com/mltsvnn/revenue-reputation-analysis.git
     ```
   - Перейдите в папку проекта:
     ```bash
     cd revenue-reputation-analysis
     ```

2. **Создание виртуального окружения и установка зависимостей**  
   - Если у вас Python 3:
     - На Windows:
       ```bash
       python -m venv venv
       venv\Scripts\activate
       ```
     - На macOS/Linux:
       ```bash
       python3 -m venv venv
       source venv/bin/activate
       ```
   - После активации окружения (вы увидите `(venv)`):
     ```bash
     pip install -r requirements.txt
     ```
   - Если вместо requirements.txt у вас environment.yml (conda):
     ```bash
     conda env create -f environment.yml
     conda activate имя_окружения
     ```

3. **Запуск Jupyter Notebook**  
   - Убедитесь, что активировано виртуальное окружение.  
   - Запустите:
     ```bash
     jupyter notebook
     ```
   - В браузере откроется список ноутбуков. Откройте нужный (например, `notebooks/data_cleaning.ipynb`) и выполняйте ячейки по порядку.

4. **Данные**  
   - Если у вас есть готовый файл `data/aggregated_data.csv`, поместите его в папку `data/`.  
   - Если вы хотите запустить парсинг самостоятельно, откройте `notebooks/data_collection.ipynb` и следуйте инструкциям (убедитесь, что у вас есть доступ к API или разрешение на парсинг).  
   - Если парсинг нежелателен или ресурсоёмок, просто используйте уже подготовленный CSV.

5. **Дополнительно**  
   - Убедитесь, что не храните секреты в коде (API-ключи), если они нужны для парсинга, опишите в README, где пользователь должен их добавить (например, в файл `.env`, который указан в `.gitignore`).  
   - После запуска всех ноутбуков результаты и графики сохранятся в ноутбуках. Вы можете экспортировать ноутбук в HTML/PDF, если нужно поделиться отчётом.

